{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "87fd5ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved cleaned CSV with selected columns to 'donnees_nettoyee.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv('donnees_vol_mitm.csv')  # use your actual filename if different\n",
    "df['is_attack'] = 0\n",
    "# List of columns to keep\n",
    "columns_to_keep = [\n",
    "    \"mission_id\", \"time\", \"real_x\", \"real_y\", \"real_z\",\n",
    "    \"target_x\", \"target_y\", \"target_z\",\n",
    "    \"vx\", \"vy\", \"vz\", \"ax\", \"ay\", \"az\",\n",
    "    \"roll\", \"pitch\", \"yaw\",\n",
    "    \"wind_x\", \"wind_y\", \"wind_z\",\n",
    "    \"erreur_m\", \"velocity\", \"rain\", \"fog\", \"snow\",\n",
    "    \"is_attack\"      \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "filtered_df = df[columns_to_keep]\n",
    "\n",
    "\n",
    "print(\" Saved cleaned CSV with selected columns to 'donnees_nettoyee.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f7adbc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Colonnes contenant des NaN :\n",
      "['snow']\n",
      "\n",
      "Nombre de NaN par colonne :\n",
      "snow    3537\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().any().any())\n",
    "colonnes_avec_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Afficher les colonnes concernées\n",
    "print(\"Colonnes contenant des NaN :\")\n",
    "print(colonnes_avec_nan)\n",
    "\n",
    "# Afficher le nombre de NaN par colonne\n",
    "print(\"\\nNombre de NaN par colonne :\")\n",
    "print(df[colonnes_avec_nan].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b22c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Colonnes avec NaN AVANT traitement :\n",
      "snow    3537\n",
      "dtype: int64\n",
      "\n",
      "✅ Colonnes avec NaN APRÈS traitement :\n",
      "Series([], dtype: int64)\n",
      "\n",
      "✅ Fichier nettoyé enregistré sous 'fichier_sans_nan.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = filtered_df  # Remplace par ton vrai nom de fichier\n",
    "\n",
    "# Afficher les colonnes contenant des NaN avant traitement\n",
    "print(\"🔍 Colonnes avec NaN AVANT traitement :\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])\n",
    "\n",
    "# === MÉTHODE DE REMPLISSAGE ===\n",
    "# Option 1 : Remplir avec la moyenne de chaque colonne numérique\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Option 2 (alternative) : remplir avec 0 — décommente si tu préfères\n",
    "# df = df.fillna(0)\n",
    "\n",
    "# Option 3 (alternative) : remplir avec la médiane\n",
    "# df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Afficher les colonnes contenant encore des NaN après traitement\n",
    "print(\"\\n✅ Colonnes avec NaN APRÈS traitement :\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])\n",
    "\n",
    "# Sauvegarder le DataFrame propre\n",
    "print(\"\\n✅ Fichier nettoyé enregistré sous 'fichier_sans_nan.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5dc9d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned flight data with new mission IDs to 'cleaned_flight_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = filtered_df\n",
    "\n",
    "# Final list of valid flight rows\n",
    "output_rows = []\n",
    "\n",
    "# Track current block of rows\n",
    "current_block = []\n",
    "current_id = None\n",
    "\n",
    "# Counter for assigning new clean mission_ids\n",
    "new_flight_id = 1\n",
    "\n",
    "# Go through rows one by one\n",
    "for _, row in df.iterrows():\n",
    "    row_id = row['mission_id']\n",
    "\n",
    "    if current_id is None:\n",
    "        current_id = row_id\n",
    "        current_block.append(row)\n",
    "    elif row_id == current_id:\n",
    "        current_block.append(row)\n",
    "    else:\n",
    "        # ID changed, time to process the current block\n",
    "        if len(current_block) == 21:\n",
    "            for r in current_block:\n",
    "                r['mission_id'] = new_flight_id\n",
    "                output_rows.append(r)\n",
    "            new_flight_id += 1\n",
    "\n",
    "        # Start a new block\n",
    "        current_block = [row]\n",
    "        current_id = row_id\n",
    "\n",
    "# Handle the last block\n",
    "if len(current_block) == 21:\n",
    "    for r in current_block:\n",
    "        r['mission_id'] = new_flight_id\n",
    "        output_rows.append(r)\n",
    "\n",
    "# Convert to DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "\n",
    "print(\"✅ Saved cleaned flight data with new mission IDs to 'cleaned_flight_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f4899ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Colonnes contenant des NaN :\n",
      "['snow']\n",
      "\n",
      "Nombre de NaN par colonne :\n",
      "snow    3537\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().any().any())\n",
    "colonnes_avec_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Afficher les colonnes concernées\n",
    "print(\"Colonnes contenant des NaN :\")\n",
    "print(colonnes_avec_nan)\n",
    "\n",
    "# Afficher le nombre de NaN par colonne\n",
    "print(\"\\nNombre de NaN par colonne :\")\n",
    "print(df[colonnes_avec_nan].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0ff79425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'erreur_m' recalculée et sauvegardée dans 'donnees_vols_avec_erreur_calculee.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "df = output_df\n",
    "\n",
    "# Vérifier que les colonnes nécessaires existent\n",
    "colonnes_requises = [\"real_x\", \"real_y\", \"real_z\", \"target_x\", \"target_y\", \"target_z\"]\n",
    "for col in colonnes_requises:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"La colonne '{col}' est manquante dans le fichier CSV.\")\n",
    "\n",
    "\n",
    "df[\"erreur_m\"] = np.sqrt(\n",
    "    (df[\"real_x\"] - df[\"target_x\"])**2 +\n",
    "    (df[\"real_y\"] - df[\"target_y\"])**2 +\n",
    "    (df[\"real_z\"] - df[\"target_z\"])**2\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"donnees_vol_multiple_filtered_R.csv\", index=False)\n",
    "print(\"✅ 'erreur_m' recalculée et sauvegardée dans 'donnees_vols_avec_erreur_calculee.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "658ddaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne finale des erreurs : 9.69 mètres\n",
      "Nombre de vols restants : 267\n",
      "Fichier 'donnees_vols_valides_Rate.csv' enregistré avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "df = output_df\n",
    "df[\"erreur_m\"] = pd.to_numeric(df[\"erreur_m\"], errors=\"coerce\")\n",
    "\n",
    "# Liste des vols valides\n",
    "vols_valides = []\n",
    "\n",
    "# Vérification des conditions sur chaque vol\n",
    "for mission_id, groupe in df.groupby(\"mission_id\"):\n",
    "    groupe_sorted = groupe.sort_values(\"time\")\n",
    "    premiers_wp = groupe_sorted.head(6)\n",
    "\n",
    "    moyenne_vol = groupe_sorted[\"erreur_m\"].round(2).mean()\n",
    "    condition_moyenne = moyenne_vol >= 15\n",
    "\n",
    "\n",
    "    # Appliquer le OU : on supprime le vol si l'une des deux conditions est vraie\n",
    "    if  condition_moyenne:\n",
    "        continue\n",
    "\n",
    "    # Sinon, garder ce vol\n",
    "    vols_valides.append(mission_id)\n",
    "\n",
    "# Filtrer le DataFrame avec les vols valides\n",
    "df_final = df[df[\"mission_id\"].isin(vols_valides)]\n",
    "\n",
    "# Sauvegarder dans un nouveau fichier CSV\n",
    "df_final.to_csv(\"donnees_vols_valides_Rate.csv\", index=False)\n",
    "\n",
    "# Affichage de la moyenne d'erreur et du nombre de vols gardés\n",
    "moyenne_finale = df_final[\"erreur_m\"].mean()\n",
    "print(f\"Moyenne finale des erreurs : {moyenne_finale:.2f} mètres\")\n",
    "print(f\"Nombre de vols restants : {len(vols_valides)}\")\n",
    "print(\"Fichier 'donnees_vols_valides_Rate.csv' enregistré avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "28ec497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Correction appliquée à 5121 points avec erreur > 2.5m\n",
      "✅ Shape des données corrigées: (5121, 3)\n"
     ]
    }
   ],
   "source": [
    "condition = df_final['erreur_m'] > 2.5\n",
    "df_final.loc[condition, ['real_x', 'real_y', 'real_z']] = df_final.loc[condition, ['target_x', 'target_y', 'target_z']].values\n",
    "print(f\"\\n✅ Correction appliquée à {condition.sum()} points avec erreur > 2.5m\")\n",
    "print(f\"✅ Shape des données corrigées: {df_final.loc[condition, ['real_x', 'real_y', 'real_z']].shape}\")\n",
    "df_final.to_csv(\"donnees_vols_valides_Rate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ffc3c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Colonnes contenant des NaN :\n",
      "['snow']\n",
      "\n",
      "Nombre de NaN par colonne :\n",
      "snow    735\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.isna().any().any())\n",
    "colonnes_avec_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Afficher les colonnes concernées\n",
    "print(\"Colonnes contenant des NaN :\")\n",
    "print(colonnes_avec_nan)\n",
    "\n",
    "# Afficher le nombre de NaN par colonne\n",
    "print(\"\\nNombre de NaN par colonne :\")\n",
    "print(df[colonnes_avec_nan].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe927b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2fae8e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\nimport pandas as pd\\nimport numpy as np\\n\\ndef main():\\n    # 1. Charger les données\\n    df = pd.read_csv(\\'donnees_vols_valides_R.csv\\')\\n\\n    # 2. Calcul de la matrice de corrélation\\n    corr = df.corr()\\n    print(\"Matrice de corrélation :\")\\n    print(corr)\\n    print(\"\\n\" + \"=\"*80 + \"\\n\")\\n\\n    # 3. Extraction des paires de variables (sans doublons ni diagonale)\\n    mask = np.triu(np.ones(corr.shape), k=1).astype(bool)\\n    corr_pairs = (\\n        corr.where(mask)\\n            .stack()\\n            .reset_index()\\n            .rename(columns={\\'level_0\\': \\'Variable1\\', \\'level_1\\': \\'Variable2\\', 0: \\'Corrélation\\'})\\n    )\\n\\n    # 4. Filtrage des paires avec corrélation >= 0.7 en valeur absolue\\n    high_corr = corr_pairs[corr_pairs[\\'Corrélation\\'].abs() >= 0.7]         .sort_values(by=\\'Corrélation\\', ascending=False)\\n\\n    # 5. Affichage des paires à forte corrélation\\n    print(\"Paires de variables avec |corrélation| ≥ 0.7 :\")\\n    for _, row in high_corr.iterrows():\\n        v1, v2, r = row[\\'Variable1\\'], row[\\'Variable2\\'], row[\\'Corrélation\\']\\n        print(f\"  - {v1} ↔ {v2} : corrélation = {r:.3f}\")\\n\\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # 1. Charger les données\n",
    "    df = pd.read_csv('donnees_vols_valides_R.csv')\n",
    "\n",
    "    # 2. Calcul de la matrice de corrélation\n",
    "    corr = df.corr()\n",
    "    print(\"Matrice de corrélation :\")\n",
    "    print(corr)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # 3. Extraction des paires de variables (sans doublons ni diagonale)\n",
    "    mask = np.triu(np.ones(corr.shape), k=1).astype(bool)\n",
    "    corr_pairs = (\n",
    "        corr.where(mask)\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={'level_0': 'Variable1', 'level_1': 'Variable2', 0: 'Corrélation'})\n",
    "    )\n",
    "\n",
    "    # 4. Filtrage des paires avec corrélation >= 0.7 en valeur absolue\n",
    "    high_corr = corr_pairs[corr_pairs['Corrélation'].abs() >= 0.7] \\\n",
    "        .sort_values(by='Corrélation', ascending=False)\n",
    "\n",
    "    # 5. Affichage des paires à forte corrélation\n",
    "    print(\"Paires de variables avec |corrélation| ≥ 0.7 :\")\n",
    "    for _, row in high_corr.iterrows():\n",
    "        v1, v2, r = row['Variable1'], row['Variable2'], row['Corrélation']\n",
    "        print(f\"  - {v1} ↔ {v2} : corrélation = {r:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4f99eb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Groupement terminé. 801 groupes créés à partir de 267 missions.\n",
      "✅ Colonnes supprimées : ['groupe_id', 'waypoint_id_1', 'waypoint_id_2', 'waypoint_id_3', 'waypoint_id_4', 'waypoint_id_5', 'waypoint_id_6', 'waypoint_id_7', 'groupe_id_1', 'groupe_id_2', 'groupe_id_3', 'groupe_id_4', 'groupe_id_5', 'groupe_id_6', 'groupe_id_7', 'groupe_unique_id_1', 'groupe_unique_id_2', 'groupe_unique_id_3', 'groupe_unique_id_4', 'groupe_unique_id_5', 'groupe_unique_id_6', 'groupe_unique_id_7']\n",
      "                       0             1\n",
      "mission_id  1.000000e+00  1.000000e+00\n",
      "time_1      1.745179e+09  1.745179e+09\n",
      "time_2      1.745179e+09  1.745179e+09\n",
      "time_3      1.745179e+09  1.745179e+09\n",
      "time_4      1.745179e+09  1.745179e+09\n",
      "...                  ...           ...\n",
      "snow_4      1.970000e-01  1.970000e-01\n",
      "snow_5      1.970000e-01  1.970000e-01\n",
      "snow_6      1.970000e-01  1.970000e-01\n",
      "snow_7      1.970000e-01  1.970000e-01\n",
      "is_attack   0.000000e+00  0.000000e+00\n",
      "\n",
      "[170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv('donnees_vols_valides_Rate.csv')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Ajouter l'index du waypoint par mission\n",
    "df['waypoint_id'] = df.groupby('mission_id').cumcount()\n",
    "\n",
    "# Regrouper les waypoints par paquets de 7 (3 groupes pour 21 waypoints)\n",
    "df['groupe_id'] = df['waypoint_id'] // 7\n",
    "df['groupe_unique_id'] = df['mission_id'].astype(str) + '_' + df['groupe_id'].astype(str)\n",
    "\n",
    "# Colonnes à pivoter (on exclut les identifiants)\n",
    "cols_to_pivot = [col for col in df.columns if col not in ['mission_id', 'is_attack']]\n",
    "\n",
    "# Stocker les résultats\n",
    "result_dfs = []\n",
    "\n",
    "# Utiliser groupby() au lieu d'une boucle sur les valeurs uniques\n",
    "for (mission_id, groupe_id), groupe_df in df.groupby(['mission_id', 'groupe_id']):\n",
    "    if len(groupe_df) > 0:\n",
    "        is_attack = groupe_df['is_attack'].iloc[0]\n",
    "        groupe_dict = {'mission_id': mission_id, 'groupe_id': groupe_id, 'is_attack': is_attack}\n",
    "\n",
    "        for col in cols_to_pivot:\n",
    "            for i, (_, row) in enumerate(groupe_df.iterrows()):\n",
    "                if i < 7:\n",
    "                    groupe_dict[f\"{col}_{i+1}\"] = row[col]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        result_dfs.append(groupe_dict)\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df_grouped = pd.DataFrame(result_dfs)\n",
    "\n",
    "# Trier par mission et groupe\n",
    "df_grouped = df_grouped.sort_values(['mission_id', 'groupe_id']).reset_index(drop=True)\n",
    "\n",
    "cols = [col for col in df_grouped.columns if col != 'is_attack'] + ['is_attack']\n",
    "df_grouped = df_grouped[cols]\n",
    "\n",
    "df_grouped.to_csv(\"vols_groupes_par_7.csv\", index=False)\n",
    "\n",
    "cols_to_drop = [col for col in df_grouped.columns if col.startswith(('groupe_id', 'groupe_unique_id', 'waypoint_id')) and col != 'mission_id']\n",
    "df_grouped_clean = df_grouped.drop(columns=cols_to_drop)\n",
    "\n",
    "df_grouped.to_csv(\"vols_groupes_par_7.csv\", index=False)\n",
    "\n",
    "# Affichage\n",
    "print(f\"✅ Groupement terminé. {len(df_grouped_clean)} groupes créés à partir de {df['mission_id'].nunique()} missions.\")\n",
    "print(f\"✅ Colonnes supprimées : {cols_to_drop}\")\n",
    "print(df_grouped_clean.head(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "14891b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ is_attack = 1 uniquement si toutes les target_x_i sont des entiers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"vols_groupes_par_7.csv\")\n",
    "\n",
    "target_x_cols = [f\"target_x_{i}\" for i in range(1, 8)]\n",
    "\n",
    "def detect_attack(row):\n",
    "    for col in target_x_cols:\n",
    "        val = row[col]\n",
    "        # Si la valeur n’est pas un entier (ex: 5.1), c’est pas une attaque\n",
    "        if not float(val).is_integer():\n",
    "            return 0\n",
    "    return 1  # Si toutes les valeurs sont entières\n",
    "\n",
    "df['is_attack'] = df.apply(detect_attack, axis=1)\n",
    "\n",
    "df.to_csv(\"vols_groupes_mis.csv\", index=False)\n",
    "print(\"✅ is_attack = 1 uniquement si toutes les target_x_i sont des entiers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a0d4bb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=pd.read_csv('vols_groupes_mis.csv')\n",
    "g['is_attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e7032665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données désaplaties et filtrées avec succès : 5607 waypoints sauvegardés.\n",
      "   mission_id          time  real_x  real_y  real_z        vx        vy  \\\n",
      "0           1  1.745179e+09     0.0     0.0    -5.0  0.274891 -0.002897   \n",
      "1           1  1.745179e+09     2.0     0.0    -5.0  0.274891 -0.002897   \n",
      "2           1  1.745179e+09     4.0     0.0    -5.0  0.274891 -0.002897   \n",
      "3           1  1.745179e+09     6.0     0.0    -5.0  0.274891 -0.002897   \n",
      "4           1  1.745179e+09     8.0     0.0    -5.0  0.274891 -0.002897   \n",
      "\n",
      "         vz        ax        ay  ...       yaw    wind_x    wind_y    wind_z  \\\n",
      "0  0.334512 -0.051712  0.018813  ... -3.119629  2.709812  1.738482  0.427165   \n",
      "1  0.334512 -0.088959 -0.030237  ... -3.119629  3.098014  1.627995  0.498919   \n",
      "2  0.334512 -0.088959 -0.030237  ... -3.119629  3.296738  1.796560  0.459864   \n",
      "3  0.334512 -0.077355 -0.099897  ... -3.119636  2.927465  2.284593  0.499880   \n",
      "4  0.334512 -0.156777 -0.017914  ... -3.119636  2.929180  1.724429  0.494355   \n",
      "\n",
      "   erreur_m  velocity  rain    fog   snow  is_attack  \n",
      "0  2.542878      5.92  0.04  0.191  0.197          1  \n",
      "1  3.498654      5.92  0.04  0.191  0.197          1  \n",
      "2  5.100483      5.92  0.04  0.191  0.197          1  \n",
      "3  6.912979      5.92  0.04  0.191  0.197          1  \n",
      "4  8.807022      5.92  0.04  0.191  0.197          1  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier aplati\n",
    "df_flat = pd.read_csv(\"vols_groupes_mis.csv\")\n",
    "\n",
    "# Liste des colonnes de base à extraire (sans le suffixe _1, _2, _3)\n",
    "base_cols = [\n",
    "    \"mission_id\", \"time\", \"real_x\", \"real_y\", \"real_z\",\n",
    "    \"target_x\", \"target_y\", \"target_z\",\n",
    "    \"vx\", \"vy\", \"vz\", \"ax\", \"ay\", \"az\",\n",
    "    \"roll\", \"pitch\", \"yaw\",\n",
    "    \"wind_x\", \"wind_y\", \"wind_z\",\n",
    "    \"erreur_m\", \"velocity\", \"rain\", \"fog\", \"snow\"\n",
    "]\n",
    "\n",
    "# Stocker les lignes reconstituées\n",
    "rows = []\n",
    "\n",
    "# Pour chaque ligne du fichier aplati (correspond à un groupe)\n",
    "for _, row in df_flat.iterrows():\n",
    "    mission_id = row[\"mission_id\"]\n",
    "    is_attack = row[\"is_attack\"]\n",
    "    \n",
    "    for i in range(1, 8):  # jusqu'à 7 waypoints\n",
    "        waypoint = {\"mission_id\": mission_id, \"is_attack\": is_attack}\n",
    "        valid = False\n",
    "        \n",
    "        for col in base_cols:\n",
    "            col_name = f\"{col}_{i}\"\n",
    "            if col_name in row:\n",
    "                waypoint[col] = row[col_name]\n",
    "                valid = True\n",
    "        \n",
    "        if valid:\n",
    "            rows.append(waypoint)\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df_unflattened = pd.DataFrame(rows)\n",
    "\n",
    "# Réorganiser les colonnes pour correspondre à l'ordre voulu\n",
    "final_columns = [\n",
    "    \"mission_id\", \"time\", \"real_x\", \"real_y\", \"real_z\",\n",
    "    \"vx\", \"vy\", \"vz\", \"ax\", \"ay\", \"az\",\n",
    "    \"roll\", \"pitch\", \"yaw\",\n",
    "    \"wind_x\", \"wind_y\", \"wind_z\",\n",
    "    \"erreur_m\", \"velocity\", \"rain\", \"fog\", \"snow\",\n",
    "    \"is_attack\"\n",
    "]\n",
    "df_unflattened = df_unflattened[final_columns]\n",
    "\n",
    "# Réinitialiser l'index\n",
    "df_unflattened = df_unflattened.reset_index(drop=True)\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "df_unflattened.to_csv(\"vols_reconstruits_filtrés.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Données désaplaties et filtrées avec succès : {len(df_unflattened)} waypoints sauvegardés.\")\n",
    "print(df_unflattened.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c1309993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vols aplatis avec succès ! (avec un seul is_attack par vol)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"donnees_vols_valides_Rate.csv\")\n",
    "\n",
    "# Réinitialiser l'index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Garder la valeur is_attack originale par mission_id\n",
    "is_attack_values = df.groupby('mission_id')['is_attack'].first().reset_index()\n",
    "\n",
    "# Ajouter un compteur par mission_id (position du waypoint)\n",
    "df['ligne_id'] = df.groupby('mission_id').cumcount()\n",
    "\n",
    "# Passer de long à wide : chaque ligne devient un vol à plat\n",
    "df_flat = df.pivot(index='mission_id', columns='ligne_id')\n",
    "\n",
    "# Aplatir les colonnes multi-niveaux\n",
    "df_flat.columns = [f\"{col}_{i}\" for col, i in df_flat.columns]\n",
    "\n",
    "# Réinitialiser l'index pour fusionner\n",
    "df_flat = df_flat.reset_index()\n",
    "\n",
    "# Fusionner avec les valeurs originales de is_attack\n",
    "df_flat = pd.merge(df_flat, is_attack_values, on='mission_id', how='left')\n",
    "\n",
    "# Supprimer toutes les colonnes is_attack_X qui ont été créées par le pivot\n",
    "cols_to_drop = [col for col in df_flat.columns if col.startswith('is_attack_')]\n",
    "df_flat = df_flat.drop(columns=cols_to_drop)\n",
    "\n",
    "# Sauvegarder le fichier aplati\n",
    "df_flat.to_csv(\"vols_aplatis_R.csv\", index=False)\n",
    "\n",
    "print(\"✅ Vols aplatis avec succès ! (avec un seul is_attack par vol)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "16eab36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Colonnes contenant des NaN :\n",
      "['snow']\n",
      "\n",
      "Nombre de NaN par colonne :\n",
      "snow    735\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.isna().any().any())\n",
    "colonnes_avec_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Afficher les colonnes concernées\n",
    "print(\"Colonnes contenant des NaN :\")\n",
    "print(colonnes_avec_nan)\n",
    "\n",
    "# Afficher le nombre de NaN par colonne\n",
    "print(\"\\nNombre de NaN par colonne :\")\n",
    "print(df[colonnes_avec_nan].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4357cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
